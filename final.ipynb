{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import glob\n",
    "import tqdm\n",
    "import torch\n",
    "import json\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import tensorboard\n",
    "\n",
    "\n",
    "# import package\n",
    "\n",
    "# model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "from torch import optim\n",
    "\n",
    "# dataset and transformation\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import os\n",
    "\n",
    "# display images\n",
    "from torchvision import utils\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# utils\n",
    "import numpy as np\n",
    "from torchsummary import summary\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import time\n",
    "import copy\n",
    "\n",
    "from model import *\n",
    "from dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mobilenet(alpha=2, num_classes=5):\n",
    "    return MobileNet(alpha, num_classes)\n",
    "\n",
    "decive = 'cuda'\n",
    "writer = SummaryWriter()\n",
    "losss = {}\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = mobilenet().to(device)\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),])\n",
    "dataset = KwenDataset(path = 'dataset', transform= transform, len_wqi = 8,lstm = True, label_type = False)\n",
    "\n",
    "dataset_size = len(dataset)\n",
    "train_size = int(dataset_size * 0.8)\n",
    "validation_size = int(dataset_size * 0.1)\n",
    "test_size = dataset_size - train_size - validation_size\n",
    "train_dataset, validation_dataset, test_dataset = random_split(dataset, [train_size, validation_size, test_size])\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, drop_last=True)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=4, shuffle=True, drop_last=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=4, shuffle=True, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n"
     ]
    }
   ],
   "source": [
    "model = mobilenet().to(device)\n",
    "\n",
    "\n",
    "#criterion = nn.MSELoss().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.0005\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "count_idx = 0\n",
    "count_idx2 = 0\n",
    "\n",
    "model = model.train()\n",
    "for epoch in tqdm.tqdm(range(1000)):\n",
    "    \n",
    "    cost = 0.0\n",
    "    model.train()\n",
    "    \n",
    "    for batch_idx, batch in enumerate(train_dataloader):\n",
    "        print(batch_idx)\n",
    "        count_idx +=1\n",
    "        \n",
    "        img = batch[0]\n",
    "        wqi =batch[1]\n",
    "        label = batch[2]\n",
    "        \n",
    "        label = label.to(device)\n",
    "        label = label.to(torch.int64)\n",
    "        \n",
    "        x_= torch.stack(wqi).to(device)\n",
    "        x_ = torch.transpose(x_,0,1)\n",
    "        x_ = x_.to(torch.float32)\n",
    "\n",
    "        x = img\n",
    "        x = x.to(device)\n",
    "        \n",
    "        data = [x, x_]\n",
    "        output = model(data)\n",
    "        output = output.to(torch.float32)\n",
    "\n",
    "\n",
    "        #output = output.view(-1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        loss = criterion(output, label)\n",
    "        \n",
    "        loss = loss.to(torch.float32)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        #scheduler.step(loss)\n",
    "        \n",
    "        #print('Loss: ', loss, 'epoch: ', epoch, \"lr: \", optimizer.param_groups[0]['lr'])\n",
    "        #print('output: ', output[0:5])\n",
    "        #print('label : ', label[0:5])\n",
    "        if count_idx%30 == 1 :\n",
    "            optimizer.param_groups[0]['lr'] *= 0.99\n",
    "        \n",
    "        if count_idx%100 ==1 and count_idx >100:\n",
    "\n",
    "            writer.add_scalar('train_loss', loss, epoch)\n",
    "            print('train:\\t',loss, epoch)\n",
    "            print('train:{}////{}'.format(output[:4],label[:4]))\n",
    "            break\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for batch_v in validation_dataloader:\n",
    "            count_idx2 +=1\n",
    "            img = batch_v[0]\n",
    "            wqi =batch_v[1]\n",
    "            label = batch_v[2]\n",
    "\n",
    "            label = label.to(torch.float32)\n",
    "            \n",
    "            label = label.to(device)\n",
    "\n",
    "            x_= torch.stack(wqi).to(device)\n",
    "            x_ = torch.transpose(x_,0,1)\n",
    "            x_ = x_.to(torch.float32)\n",
    "\n",
    "            x = img\n",
    "            x = x.to(device)\n",
    "\n",
    "            data = [x, x_]\n",
    "            output = model(data)\n",
    "            output = output.view(-1)\n",
    "            \n",
    "            loss = criterion(output, label)\n",
    "\n",
    "            loss = loss.to(torch.float32)\n",
    "            if count_idx2%100 ==1 and count_idx2 >100:          \n",
    "                writer.add_scalar('validation_loss', loss, epoch)\n",
    "                print('evaluate:\\t', loss, epoch)\n",
    "                break\n",
    "    \n",
    "torch.save(model, os.path.join('model_save', 'model.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Softmax(\n",
       "  dim=tensor([[ 8.1953e-04,  1.1585e-04, -1.6642e-04, -9.9622e-05, -9.1605e-04],\n",
       "          [ 6.8341e-04,  2.9948e-04, -3.7609e-04,  7.7140e-05, -5.3084e-04],\n",
       "          [ 8.8212e-04,  2.1449e-04,  1.5408e-04,  1.0190e-04, -1.2858e-03],\n",
       "          [ 7.2188e-04,  1.2843e-04,  2.0496e-05,  1.1666e-04, -8.1953e-04],\n",
       "          [ 8.8163e-04, -1.8742e-04, -8.4497e-05,  6.9156e-05, -7.9518e-04],\n",
       "          [ 1.5685e-03, -1.7716e-03, -1.3095e-03,  1.0438e-03, -1.7935e-03],\n",
       "          [ 5.5871e-04,  6.7618e-05, -4.6266e-04,  1.4725e-04, -7.3185e-04],\n",
       "          [ 9.0222e-04, -9.1765e-05, -2.7312e-04,  2.1300e-04, -1.0455e-03],\n",
       "          [ 8.5473e-04,  3.2693e-04, -2.7685e-04,  4.2735e-04, -6.6907e-04],\n",
       "          [ 4.8543e-04,  8.9527e-05, -1.9716e-04, -3.9301e-04, -3.7348e-04],\n",
       "          [ 1.1271e-03, -2.3277e-04, -4.8019e-04,  1.9916e-04, -7.0473e-04],\n",
       "          [ 1.2991e-03, -7.1030e-05, -4.7138e-06,  6.7375e-06, -8.6921e-04],\n",
       "          [ 6.3944e-04,  3.5273e-04, -3.2510e-05,  1.4168e-04, -9.2418e-04],\n",
       "          [ 6.5465e-04, -4.4654e-05, -2.1970e-04,  1.8922e-04, -3.2397e-04],\n",
       "          [ 6.4198e-04, -2.0653e-04, -3.7052e-04,  2.5677e-04, -5.2138e-04],\n",
       "          [ 3.3279e-04,  3.4890e-04, -1.4864e-04, -1.7817e-04, -1.4148e-04]],\n",
       "         device='cuda:0', grad_fn=<AddmmBackward0>)\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Softmax(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 16])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected input batch_size (5) to match target batch_size (16).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m criterion(out2,label)\n",
      "File \u001b[1;32mc:\\Users\\tlseh\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\tlseh\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:1174\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1173\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m-> 1174\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mcross_entropy(\u001b[39minput\u001b[39;49m, target, weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[0;32m   1175\u001b[0m                            ignore_index\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mignore_index, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction,\n\u001b[0;32m   1176\u001b[0m                            label_smoothing\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlabel_smoothing)\n",
      "File \u001b[1;32mc:\\Users\\tlseh\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:3029\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3027\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   3028\u001b[0m     reduction \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3029\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mcross_entropy_loss(\u001b[39minput\u001b[39;49m, target, weight, _Reduction\u001b[39m.\u001b[39;49mget_enum(reduction), ignore_index, label_smoothing)\n",
      "\u001b[1;31mValueError\u001b[0m: Expected input batch_size (5) to match target batch_size (16)."
     ]
    }
   ],
   "source": [
    "criterion(out2,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(os.path.join('model_save', 'model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileNet(\n",
       "  (conv1): BasicConv2d(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6()\n",
       "    )\n",
       "  )\n",
       "  (conv2): Depthwise(\n",
       "    (depthwise): Sequential(\n",
       "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6()\n",
       "    )\n",
       "    (pointwise): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6()\n",
       "    )\n",
       "    (seblock): SEBlock(\n",
       "      (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "      (excitation): Sequential(\n",
       "        (0): Linear(in_features=128, out_features=8, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=8, out_features=128, bias=True)\n",
       "        (3): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conv3): Sequential(\n",
       "    (0): Depthwise(\n",
       "      (depthwise): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6()\n",
       "      )\n",
       "      (pointwise): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6()\n",
       "      )\n",
       "      (seblock): SEBlock(\n",
       "        (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (excitation): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=16, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=16, out_features=256, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): Depthwise(\n",
       "      (depthwise): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6()\n",
       "      )\n",
       "      (pointwise): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6()\n",
       "      )\n",
       "      (seblock): SEBlock(\n",
       "        (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (excitation): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=16, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=16, out_features=256, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conv4): Sequential(\n",
       "    (0): Depthwise(\n",
       "      (depthwise): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6()\n",
       "      )\n",
       "      (pointwise): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6()\n",
       "      )\n",
       "      (seblock): SEBlock(\n",
       "        (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (excitation): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=512, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): Depthwise(\n",
       "      (depthwise): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6()\n",
       "      )\n",
       "      (pointwise): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6()\n",
       "      )\n",
       "      (seblock): SEBlock(\n",
       "        (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (excitation): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=512, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conv5): Sequential(\n",
       "    (0): Depthwise(\n",
       "      (depthwise): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6()\n",
       "      )\n",
       "      (pointwise): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6()\n",
       "      )\n",
       "      (seblock): SEBlock(\n",
       "        (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (excitation): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=64, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=64, out_features=1024, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): Depthwise(\n",
       "      (depthwise): Sequential(\n",
       "        (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6()\n",
       "      )\n",
       "      (pointwise): Sequential(\n",
       "        (0): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6()\n",
       "      )\n",
       "      (seblock): SEBlock(\n",
       "        (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (excitation): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=64, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=64, out_features=1024, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): Depthwise(\n",
       "      (depthwise): Sequential(\n",
       "        (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6()\n",
       "      )\n",
       "      (pointwise): Sequential(\n",
       "        (0): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6()\n",
       "      )\n",
       "      (seblock): SEBlock(\n",
       "        (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (excitation): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=64, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=64, out_features=1024, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): Depthwise(\n",
       "      (depthwise): Sequential(\n",
       "        (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6()\n",
       "      )\n",
       "      (pointwise): Sequential(\n",
       "        (0): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6()\n",
       "      )\n",
       "      (seblock): SEBlock(\n",
       "        (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (excitation): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=64, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=64, out_features=1024, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): Depthwise(\n",
       "      (depthwise): Sequential(\n",
       "        (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6()\n",
       "      )\n",
       "      (pointwise): Sequential(\n",
       "        (0): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6()\n",
       "      )\n",
       "      (seblock): SEBlock(\n",
       "        (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (excitation): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=64, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=64, out_features=1024, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): Depthwise(\n",
       "      (depthwise): Sequential(\n",
       "        (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6()\n",
       "      )\n",
       "      (pointwise): Sequential(\n",
       "        (0): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6()\n",
       "      )\n",
       "      (seblock): SEBlock(\n",
       "        (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (excitation): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=64, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=64, out_features=1024, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conv6): Sequential(\n",
       "    (0): Depthwise(\n",
       "      (depthwise): Sequential(\n",
       "        (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=1024, bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6()\n",
       "      )\n",
       "      (pointwise): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6()\n",
       "      )\n",
       "      (seblock): SEBlock(\n",
       "        (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (excitation): Sequential(\n",
       "          (0): Linear(in_features=2048, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=128, out_features=2048, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conv7): Sequential(\n",
       "    (0): Depthwise(\n",
       "      (depthwise): Sequential(\n",
       "        (0): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=2048, bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6()\n",
       "      )\n",
       "      (pointwise): Sequential(\n",
       "        (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6()\n",
       "      )\n",
       "      (seblock): SEBlock(\n",
       "        (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (excitation): Sequential(\n",
       "          (0): Linear(in_features=2048, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=128, out_features=2048, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (linear): Linear(in_features=2048, out_features=256, bias=True)\n",
       "  (linear2): Linear(in_features=256, out_features=16, bias=True)\n",
       "  (rnn): LSTM(256, 8, batch_first=True, bidirectional=True)\n",
       "  (lstm): RNNNet(\n",
       "    (rnn): LSTM(8, 8, batch_first=True, bidirectional=True)\n",
       "    (linear3): Linear(in_features=16, out_features=4, bias=True)\n",
       "  )\n",
       "  (linear3): Linear(in_features=32, out_features=1, bias=True)\n",
       "  (linear4): Linear(in_features=20, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate:\t tensor(2086.0508, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "evaluate:\t tensor(3408.9556, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "evaluate:\t tensor(3682.2661, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "evaluate:\t tensor(2658.1648, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "evaluate:\t tensor(2505.6021, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "evaluate:\t tensor(3346.3108, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "evaluate:\t tensor(2568.4443, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "evaluate:\t tensor(2367.9546, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "criterion = nn.MSELoss().to(device)\n",
    "learning_rate = 0.0005\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "count_idx2 =0\n",
    "for batch_v in validation_dataloader:\n",
    "    count_idx2 +=1\n",
    "    img = batch_v[0]\n",
    "    wqi =batch_v[1]\n",
    "    label = batch_v[2]\n",
    "    label = label.to(torch.float32)\n",
    "    label = label.to(device)\n",
    "    x_= torch.stack(wqi).to(device)\n",
    "    x_ = torch.transpose(x_,0,1)\n",
    "    x_ = x_.to(torch.float32)\n",
    "    x = img\n",
    "    x = x.to(device)\n",
    "    data = [x, x_]\n",
    "    output = model(data)\n",
    "    output = output.view(-1)\n",
    "    \n",
    "    loss = criterion(output, label)\n",
    "    loss = loss.to(torch.float32)\n",
    "    if count_idx2%100 ==1 and count_idx2 >100:          \n",
    "        writer.add_scalar('validation_loss', loss)\n",
    "        print('evaluate:\\t', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\t tensor(9930.1855, device='cuda:0', grad_fn=<MseLossBackward0>) 0\n",
      "tensor([-17.8807, -13.2231, -12.9292,   1.8390, -17.0089, -15.4040, -15.9822,\n",
      "        -13.8730, -15.6099, -13.0395, -16.0203, -10.5950, -15.7722, -17.4338,\n",
      "        -15.9680, -13.7483], device='cuda:0', grad_fn=<ViewBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/300 [00:38<3:13:44, 38.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate:\t tensor(8676.5361, device='cuda:0') 0\n",
      "tensor([-4.7503, -3.8051, -3.9498, -3.6029], device='cuda:0')\n",
      "tensor([90.9100, 88.0600, 86.4600, 90.9600], device='cuda:0')\n",
      "train:\t tensor(62964.1016, device='cuda:0', grad_fn=<MseLossBackward0>) 1\n",
      "tensor([-166.7610, -171.6743, -172.2168, -173.6967, -177.2820, -175.5456,\n",
      "        -163.4548, -170.2329, -139.5984, -158.4074, -174.6502, -171.0094,\n",
      "        -182.8379, -163.5651, -168.8565, -143.7478], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/300 [01:16<3:08:44, 38.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate:\t tensor(70571.0781, device='cuda:0') 1\n",
      "tensor([-158.5595, -169.5484, -191.1239, -191.6495], device='cuda:0')\n",
      "tensor([79.9900, 83.0100, 93.5100, 92.2100], device='cuda:0')\n",
      "train:\t tensor(130541.5156, device='cuda:0', grad_fn=<MseLossBackward0>) 2\n",
      "tensor([451.2589, 458.4052, 446.3334, 475.8555, 385.1453, 418.7823, 442.8664,\n",
      "        454.2672, 458.2416, 422.6135, 450.9047, 410.7699, 441.4756, 477.4974,\n",
      "        444.0422, 471.6678], device='cuda:0', grad_fn=<ViewBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 3/300 [01:56<3:13:06, 39.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate:\t tensor(135499.6250, device='cuda:0') 2\n",
      "tensor([463.9956, 430.9619, 420.2965, 497.5227], device='cuda:0')\n",
      "tensor([83.3300, 73.0200, 93.7400, 94.6200], device='cuda:0')\n",
      "train:\t tensor(37980.2969, device='cuda:0', grad_fn=<MseLossBackward0>) 3\n",
      "tensor([ -86.1032, -109.7228, -106.7410, -108.3907, -102.5755, -104.8574,\n",
      "        -106.5960, -104.0868, -108.8677, -111.9974, -110.3251, -104.9661,\n",
      "        -111.2746, -102.9966, -110.4706, -104.1249], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 4/300 [02:37<3:16:44, 39.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate:\t tensor(41833.9180, device='cuda:0') 3\n",
      "tensor([-126.7022, -111.1304, -116.0079, -118.0456], device='cuda:0')\n",
      "tensor([94.2600, 82.9200, 84.8300, 83.2500], device='cuda:0')\n",
      "train:\t tensor(107087.5938, device='cuda:0', grad_fn=<MseLossBackward0>) 4\n",
      "tensor([-255.8774, -235.5561, -266.9424, -270.6976, -251.7074, -193.0651,\n",
      "        -263.5403, -267.4698, -168.8640, -249.4688, -198.7746, -239.2564,\n",
      "        -241.8377, -252.6824, -234.7833, -258.8492], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 5/300 [03:18<3:17:16, 40.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate:\t tensor(102102.4297, device='cuda:0') 4\n",
      "tensor([-243.9975, -245.9887, -228.3985, -214.6901], device='cuda:0')\n",
      "tensor([88.1400, 85.1400, 93.2600, 76.8300], device='cuda:0')\n",
      "train:\t tensor(437074.8750, device='cuda:0', grad_fn=<MseLossBackward0>) 5\n",
      "tensor([727.8837, 821.2161, 751.0101, 772.0941, 737.1010, 296.4492, 794.8979,\n",
      "        718.8294, 791.7324, 753.9207, 761.7374, 796.0358, 765.3312, 734.4170,\n",
      "        795.4163, 722.5844], device='cuda:0', grad_fn=<ViewBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 6/300 [03:58<3:16:29, 40.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate:\t tensor(485110.8750, device='cuda:0') 5\n",
      "tensor([759.2386, 791.8399, 803.4780, 771.6506], device='cuda:0')\n",
      "tensor([69.9400, 91.1200, 93.3500, 86.0700], device='cuda:0')\n",
      "train:\t tensor(402.4924, device='cuda:0', grad_fn=<MseLossBackward0>) 6\n",
      "tensor([74.2916, 68.2620, 65.2602, 80.1770, 64.7450, 23.1778, 73.7825, 64.5730,\n",
      "        78.4147, 75.2066, 78.9154, 74.2904, 66.2827, 78.2064, 68.0345, 58.5405],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 7/300 [04:38<3:16:35, 40.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate:\t tensor(574.5071, device='cuda:0') 6\n",
      "tensor([62.2045, 60.5797, 63.6053, 58.8675], device='cuda:0')\n",
      "tensor([79.6200, 88.1700, 93.5500, 77.2200], device='cuda:0')\n",
      "train:\t tensor(541951.8125, device='cuda:0', grad_fn=<MseLossBackward0>) 7\n",
      "tensor([-694.1893, -663.2744, -677.5626, -689.2198, -622.0388, -709.4129,\n",
      "        -619.3093, -727.4532, -718.2841, -682.3912, -656.6480, -599.5650,\n",
      "        -646.4107, -669.7006, -157.2380, -666.0057], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 8/300 [05:18<3:14:39, 40.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate:\t tensor(458050.2500, device='cuda:0') 7\n",
      "tensor([-647.4762, -626.7078, -705.0720, -307.2441], device='cuda:0')\n",
      "tensor([87.8900, 80.8300, 91.0800, 88.9500], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 8/300 [05:46<3:30:33, 43.26s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m cost \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[0;32m     16\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m---> 18\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m train_dataloader:\n\u001b[0;32m     19\u001b[0m     count_idx \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m     21\u001b[0m     img \u001b[39m=\u001b[39m batch[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\tlseh\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\tlseh\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    676\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 677\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    678\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    679\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\tlseh\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\tlseh\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\tlseh\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataset.py:298\u001b[0m, in \u001b[0;36mSubset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(idx, \u001b[39mlist\u001b[39m):\n\u001b[0;32m    297\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m idx]]\n\u001b[1;32m--> 298\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindices[idx]]\n",
      "File \u001b[1;32me:\\kwen\\dataset.py:49\u001b[0m, in \u001b[0;36mKwenDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     46\u001b[0m label \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabel[file_name]\n\u001b[0;32m     48\u001b[0m img \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mopen(img_path)\n\u001b[1;32m---> 49\u001b[0m img \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39;49mresize((\u001b[39m256\u001b[39;49m,\u001b[39m192\u001b[39;49m))        \n\u001b[0;32m     50\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m     img \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform(img)\n",
      "File \u001b[1;32mc:\\Users\\tlseh\\Anaconda3\\lib\\site-packages\\PIL\\Image.py:2156\u001b[0m, in \u001b[0;36mImage.resize\u001b[1;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[0;32m   2152\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[0;32m   2154\u001b[0m size \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(size)\n\u001b[1;32m-> 2156\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload()\n\u001b[0;32m   2157\u001b[0m \u001b[39mif\u001b[39;00m box \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   2158\u001b[0m     box \u001b[39m=\u001b[39m (\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msize\n",
      "File \u001b[1;32mc:\\Users\\tlseh\\Anaconda3\\lib\\site-packages\\PIL\\ImageFile.py:269\u001b[0m, in \u001b[0;36mImageFile.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    266\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(msg)\n\u001b[0;32m    268\u001b[0m b \u001b[39m=\u001b[39m b \u001b[39m+\u001b[39m s\n\u001b[1;32m--> 269\u001b[0m n, err_code \u001b[39m=\u001b[39m decoder\u001b[39m.\u001b[39;49mdecode(b)\n\u001b[0;32m    270\u001b[0m \u001b[39mif\u001b[39;00m n \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    271\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#model = RNNNet(input_size=8, num_classes=1, hidden_size = 8, init_weights=True).to(device)\n",
    "device = 'cuda'\n",
    "model = testNet(1).to(device)\n",
    "\n",
    "criterion = nn.MSELoss().to(device)\n",
    "learning_rate = 0.01\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "#optimizer = optim.SGD(model.parameters(),lr=learning_rate)\n",
    "\n",
    "count_idx = 0\n",
    "count_idx2 = 0\n",
    "\n",
    "for epoch in tqdm.tqdm(range(300)):\n",
    "    \n",
    "    cost = 0.0\n",
    "    model.train()\n",
    "    \n",
    "    for batch in train_dataloader:\n",
    "        count_idx +=1\n",
    "        \n",
    "        img = batch[0]\n",
    "        wqi =batch[1]\n",
    "        label = batch[2]\n",
    "        \n",
    "        label = label.to(torch.float32)\n",
    "        label = label.to(device)\n",
    "        \n",
    "        x_= torch.stack(wqi).to(device)\n",
    "        x_ = torch.transpose(x_,0,1)\n",
    "        x_ = x_.to(torch.float32)\n",
    "\n",
    "        output = model(x_)\n",
    "        output = output.view(-1)\n",
    "\n",
    "        loss = criterion(output, label)\n",
    "        \n",
    "        loss = loss.to(torch.float32)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        #scheduler.step(loss)\n",
    "        \n",
    "        #print('Loss: ', loss, 'epoch: ', epoch, \"lr: \", optimizer.param_groups[0]['lr'])\n",
    "        #print('output: ', output[0:5])\n",
    "        #print('label : ', label[0:5])\n",
    "        if count_idx%30 == 1 :\n",
    "            optimizer.param_groups[0]['lr'] *= 0.99\n",
    "        \n",
    "        if count_idx%100 ==1 and count_idx >100:\n",
    "\n",
    "            writer.add_scalar('train_loss', loss, epoch)\n",
    "            print('train:\\t',loss, epoch)\n",
    "            print(output)\n",
    "            break\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for batch_v in validation_dataloader:\n",
    "            count_idx2 +=1\n",
    "            img = batch_v[0]\n",
    "            wqi =batch_v[1]\n",
    "            label = batch_v[2]\n",
    "\n",
    "            label = label.to(torch.float32)\n",
    "            label = label.to(device)\n",
    "\n",
    "            x_= torch.stack(wqi).to(device)\n",
    "            x_ = torch.transpose(x_,0,1)\n",
    "            x_ = x_.to(torch.float32)\n",
    "\n",
    "            output = model(x_)\n",
    "            output = output.view(-1)\n",
    "            \n",
    "            loss = criterion(output, label)\n",
    "\n",
    "            loss = loss.to(torch.float32)\n",
    "            if count_idx2%100 ==1 and count_idx2 >100:          \n",
    "                writer.add_scalar('validation_loss', loss, epoch)\n",
    "                print('evaluate:\\t', loss, epoch)\n",
    "                print(output)\n",
    "                print(label)\n",
    "                break\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0869],\n",
       "        [0.1284],\n",
       "        [0.1484],\n",
       "        [0.1420],\n",
       "        [0.1419],\n",
       "        [0.1232],\n",
       "        [0.0899],\n",
       "        [0.1331],\n",
       "        [0.0910],\n",
       "        [0.0974],\n",
       "        [0.1557],\n",
       "        [0.1553],\n",
       "        [0.1554],\n",
       "        [0.1545],\n",
       "        [0.1491],\n",
       "        [0.1201],\n",
       "        [0.1454],\n",
       "        [0.1333],\n",
       "        [0.1031],\n",
       "        [0.0919]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm = RNNNet(input_size=8, num_classes=1, hidden_size = 8, init_weights=True).to(device)\n",
    "lstm(x_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
