{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import glob\n",
    "import tqdm\n",
    "import torch\n",
    "import json\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import tensorboard\n",
    "\n",
    "\n",
    "# import package\n",
    "\n",
    "# model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "from torch import optim\n",
    "\n",
    "# dataset and transformation\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "# display images\n",
    "from torchvision import utils\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# utils\n",
    "import numpy as np\n",
    "from torchsummary import summary\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import time\n",
    "import copy\n",
    "\n",
    "from model import *\n",
    "from dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 \n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tlseh\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([20])) that is different to the input size (torch.Size([20, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.001\n",
      "Loss:  tensor(7448.6763, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[-6.2769e-06],\n",
      "        [ 9.1177e-05]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.000995\n",
      "Loss:  tensor(6754.6812, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[0.0162],\n",
      "        [0.0170]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.000995\n",
      "Loss:  tensor(6822.6992, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[0.0412],\n",
      "        [0.0517]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.000995\n",
      "Loss:  tensor(7553.4966, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[0.0818],\n",
      "        [0.0902]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.000995\n",
      "Loss:  tensor(7505.0024, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[0.1414],\n",
      "        [0.1472]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.000995\n",
      "Loss:  tensor(7371.4819, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[0.2441],\n",
      "        [0.2226]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.000995\n",
      "Loss:  tensor(6737.3462, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[0.3562],\n",
      "        [0.3460]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.000995\n",
      "Loss:  tensor(7247.5400, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[0.4827],\n",
      "        [0.5014]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.000995\n",
      "Loss:  tensor(6621.4307, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[0.6996],\n",
      "        [0.7038]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.000995\n",
      "Loss:  tensor(6979.8687, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[0.9343],\n",
      "        [0.9541]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.000995\n",
      "Loss:  tensor(7268.0625, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[1.2271],\n",
      "        [1.3855]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.000990025\n",
      "Loss:  tensor(6910.0317, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[1.8073],\n",
      "        [1.7793]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.000990025\n",
      "Loss:  tensor(6751.2598, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[2.3853],\n",
      "        [2.3439]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.000990025\n",
      "Loss:  tensor(6555.2412, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[3.0334],\n",
      "        [3.0211]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.000990025\n",
      "Loss:  tensor(6930.6597, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[3.6737],\n",
      "        [4.0151]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.000990025\n",
      "Loss:  tensor(6180.5098, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[5.2375],\n",
      "        [4.8145]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.000990025\n",
      "Loss:  tensor(6334.8926, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[6.3660],\n",
      "        [6.3001]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.000990025\n",
      "Loss:  tensor(6028.5571, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[8.1343],\n",
      "        [8.3303]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.000990025\n",
      "Loss:  tensor(5449.1230, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[10.5344],\n",
      "        [10.2650]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.000990025\n",
      "Loss:  tensor(4642.9790, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[13.2188],\n",
      "        [12.9679]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.000990025\n",
      "Loss:  tensor(5001.0601, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[15.4593],\n",
      "        [15.3235]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.000985074875\n",
      "Loss:  tensor(4431.1860, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[18.7136],\n",
      "        [18.5582]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.000985074875\n",
      "Loss:  tensor(4037.3843, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[22.6813],\n",
      "        [22.4162]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.000985074875\n",
      "Loss:  tensor(3836.7368, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[25.7120],\n",
      "        [26.6765]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.000985074875\n",
      "Loss:  tensor(2948.6260, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[32.2114],\n",
      "        [30.5597]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.000985074875\n",
      "Loss:  tensor(2387.2527, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[35.6443],\n",
      "        [35.9592]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.000985074875\n",
      "Loss:  tensor(2201.3708, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[38.4639],\n",
      "        [42.1210]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.000985074875\n",
      "Loss:  tensor(1609.3455, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[45.8581],\n",
      "        [47.3219]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.000985074875\n",
      "Loss:  tensor(957.9041, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[54.2283],\n",
      "        [52.5793]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.000985074875\n",
      "Loss:  tensor(646.8443, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[60.1848],\n",
      "        [59.0076]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.000985074875\n",
      "Loss:  tensor(360.6797, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[70.3051],\n",
      "        [69.6519]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.000980149500625\n",
      "Loss:  tensor(146.3863, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[77.4488],\n",
      "        [74.5388]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.000980149500625\n",
      "Loss:  tensor(72.0042, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[85.2902],\n",
      "        [85.7424]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.000980149500625\n",
      "Loss:  tensor(202.1874, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[96.5818],\n",
      "        [95.2789]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.000980149500625\n",
      "Loss:  tensor(800.5175, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[110.7017],\n",
      "        [111.2128]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.000980149500625\n",
      "Loss:  tensor(1552.4500, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[117.4360],\n",
      "        [120.9077]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.000980149500625\n",
      "Loss:  tensor(1947.3478, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[130.2746],\n",
      "        [130.3214]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.000980149500625\n",
      "Loss:  tensor(2790.8787, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[138.9046],\n",
      "        [134.2492]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.000980149500625\n",
      "Loss:  tensor(4134.5190, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[147.9015],\n",
      "        [150.2416]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.000980149500625\n",
      "Loss:  tensor(5107.8428, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[158.4392],\n",
      "        [159.6069]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.000980149500625\n",
      "Loss:  tensor(6753.2622, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[167.2705],\n",
      "        [149.5520]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.000975248753121875\n",
      "Loss:  tensor(6203.7148, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[157.9761],\n",
      "        [157.7573]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.000975248753121875\n",
      "Loss:  tensor(6137.6196, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[160.4040],\n",
      "        [156.7665]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.000975248753121875\n",
      "Loss:  tensor(5415.6562, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[166.9635],\n",
      "        [164.7070]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.000975248753121875\n",
      "Loss:  tensor(4831.8433, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[221.1940],\n",
      "        [155.0329]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.000975248753121875\n",
      "Loss:  tensor(4363.6519, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[145.7740],\n",
      "        [123.6924]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.000975248753121875\n",
      "Loss:  tensor(3032.1562, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[217.6600],\n",
      "        [ 94.4058]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.000975248753121875\n",
      "Loss:  tensor(2578.8831, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[131.8377],\n",
      "        [129.9527]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.000975248753121875\n",
      "Loss:  tensor(1777.2573, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[109.8672],\n",
      "        [107.9804]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.000975248753121875\n",
      "Loss:  tensor(1144.8708, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[77.8882],\n",
      "        [94.3046]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.000975248753121875\n",
      "Loss:  tensor(609.7311, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[131.5401],\n",
      "        [ 98.5421]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009703725093562657\n",
      "Loss:  tensor(762.2539, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[74.0319],\n",
      "        [96.6478]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009703725093562657\n",
      "Loss:  tensor(754.6002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[ 69.7036],\n",
      "        [151.5314]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009703725093562657\n",
      "Loss:  tensor(940.8232, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[69.3491],\n",
      "        [58.8412]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009703725093562657\n",
      "Loss:  tensor(762.0609, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[52.2357],\n",
      "        [59.1109]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009703725093562657\n",
      "Loss:  tensor(1242.5979, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[44.6002],\n",
      "        [47.9071]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009703725093562657\n",
      "Loss:  tensor(1254.9919, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[57.6605],\n",
      "        [63.7628]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009703725093562657\n",
      "Loss:  tensor(1858.3774, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[20.4562],\n",
      "        [42.3120]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009703725093562657\n",
      "Loss:  tensor(2216.9451, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[37.7742],\n",
      "        [40.6075]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009703725093562657\n",
      "Loss:  tensor(2545.6211, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[32.1708],\n",
      "        [32.9404]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009703725093562657\n",
      "Loss:  tensor(2727.2021, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[43.0752],\n",
      "        [33.2490]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009655206468094843\n",
      "Loss:  tensor(3116.9736, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[35.1569],\n",
      "        [21.3665]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009655206468094843\n",
      "Loss:  tensor(3583.5981, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[31.8301],\n",
      "        [11.8827]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009655206468094843\n",
      "Loss:  tensor(3941.9382, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[24.2286],\n",
      "        [29.1565]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009655206468094843\n",
      "Loss:  tensor(4227.1450, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[22.5315],\n",
      "        [23.3082]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009655206468094843\n",
      "Loss:  tensor(4626.6650, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[ 9.9605],\n",
      "        [18.9431]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009655206468094843\n",
      "Loss:  tensor(4324.7031, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[14.7539],\n",
      "        [14.1570]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009655206468094843\n",
      "Loss:  tensor(5241.6172, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[16.3859],\n",
      "        [19.0622]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009655206468094843\n",
      "Loss:  tensor(4984.3008, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[10.1750],\n",
      "        [12.0457]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009655206468094843\n",
      "Loss:  tensor(5185.7295, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[10.9316],\n",
      "        [11.0881]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009655206468094843\n",
      "Loss:  tensor(6087.6406, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[10.1396],\n",
      "        [10.0269]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009606930435754369\n",
      "Loss:  tensor(6520.1274, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[7.7045],\n",
      "        [5.9481]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009606930435754369\n",
      "Loss:  tensor(5371.8262, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[6.2488],\n",
      "        [3.2645]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009606930435754369\n",
      "Loss:  tensor(6464.4175, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[2.8918],\n",
      "        [5.4667]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009606930435754369\n",
      "Loss:  tensor(6077.6650, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[3.4931],\n",
      "        [4.5107]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009606930435754369\n",
      "Loss:  tensor(6541.1895, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[3.6151],\n",
      "        [4.3106]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009606930435754369\n",
      "Loss:  tensor(6804.4634, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[2.5234],\n",
      "        [3.1907]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009606930435754369\n",
      "Loss:  tensor(6755.0361, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[1.8473],\n",
      "        [2.9939]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009606930435754369\n",
      "Loss:  tensor(7085.9561, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[2.1757],\n",
      "        [2.2260]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009606930435754369\n",
      "Loss:  tensor(6681.6934, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[1.9133],\n",
      "        [1.7991]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009606930435754369\n",
      "Loss:  tensor(6809.8247, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[1.5781],\n",
      "        [1.4288]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009558895783575597\n",
      "Loss:  tensor(6604.0903, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[1.0040],\n",
      "        [1.4369]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009558895783575597\n",
      "Loss:  tensor(7294.8892, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[0.8695],\n",
      "        [0.9157]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009558895783575597\n",
      "Loss:  tensor(7075.0156, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[0.8956],\n",
      "        [0.8199]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009558895783575597\n",
      "Loss:  tensor(7412.3823, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[0.9214],\n",
      "        [0.9084]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009558895783575597\n",
      "Loss:  tensor(6821.8711, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[0.8226],\n",
      "        [0.8164]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009558895783575597\n",
      "Loss:  tensor(7630.4160, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[0.5742],\n",
      "        [0.5824]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009558895783575597\n",
      "Loss:  tensor(7764.0771, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[0.5528],\n",
      "        [0.6432]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009558895783575597\n",
      "Loss:  tensor(6206.7798, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[0.4542],\n",
      "        [0.5040]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009558895783575597\n",
      "Loss:  tensor(7327.5693, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[0.3880],\n",
      "        [0.4234]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009558895783575597\n",
      "Loss:  tensor(7100.8203, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[0.0636],\n",
      "        [0.3717]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009511101304657719\n",
      "Loss:  tensor(7304.5000, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[0.1967],\n",
      "        [0.0404]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009511101304657719\n",
      "Loss:  tensor(7661.5723, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[-0.2768],\n",
      "        [-0.2031]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009511101304657719\n",
      "Loss:  tensor(7508.7485, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[-0.4703],\n",
      "        [-0.4809]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009511101304657719\n",
      "Loss:  tensor(7018.1772, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[-0.8143],\n",
      "        [-2.2913]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009511101304657719\n",
      "Loss:  tensor(7891.9932, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[-1.3849],\n",
      "        [-0.9921]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009511101304657719\n",
      "Loss:  tensor(7454.4204, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[-1.3183],\n",
      "        [-1.6426]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009511101304657719\n",
      "Loss:  tensor(7760.8608, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[-3.4332],\n",
      "        [-1.9186]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009511101304657719\n",
      "Loss:  tensor(7002.9194, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[-3.4779],\n",
      "        [-2.2284]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009511101304657719\n",
      "Loss:  tensor(7642.6719, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[-2.7384],\n",
      "        [-2.6983]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009511101304657719\n",
      "Loss:  tensor(7164.1880, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[-3.5795],\n",
      "        [-4.9071]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.000946354579813443\n",
      "Loss:  tensor(7971.4761, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[-5.8164],\n",
      "        [-5.8959]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.000946354579813443\n",
      "Loss:  tensor(7929.7021, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[-6.5681],\n",
      "        [-7.8753]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.000946354579813443\n",
      "Loss:  tensor(8227.4209, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[-4.3692],\n",
      "        [-3.7564]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.000946354579813443\n",
      "Loss:  tensor(8620.0889, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[-8.5525],\n",
      "        [-6.7625]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.000946354579813443\n",
      "Loss:  tensor(8966.8955, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[ -4.8244],\n",
      "        [-13.1972]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.000946354579813443\n",
      "Loss:  tensor(9371.7441, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[-11.7201],\n",
      "        [ -8.6706]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.000946354579813443\n",
      "Loss:  tensor(8574.5723, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[-11.6543],\n",
      "        [ -9.1338]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.000946354579813443\n",
      "Loss:  tensor(9346.3213, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[-9.3376],\n",
      "        [-5.3373]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.000946354579813443\n",
      "Loss:  tensor(8668.6250, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[-10.1519],\n",
      "        [ -9.3322]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.000946354579813443\n",
      "Loss:  tensor(9691.9648, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[ -5.3413],\n",
      "        [-14.2197]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009416228069143757\n",
      "Loss:  tensor(9879.7324, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[-16.4673],\n",
      "        [ -8.4775]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009416228069143757\n",
      "Loss:  tensor(9734.5693, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[-7.3108],\n",
      "        [-5.5553]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009416228069143757\n",
      "Loss:  tensor(9843.7002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[-15.2252],\n",
      "        [-12.4979]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009416228069143757\n",
      "Loss:  tensor(9583.5596, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[-13.7108],\n",
      "        [ -7.0048]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009416228069143757\n",
      "Loss:  tensor(9959.8525, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[ -5.3986],\n",
      "        [-12.4180]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009416228069143757\n",
      "Loss:  tensor(10565.8057, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[ -6.4077],\n",
      "        [-31.2489]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009416228069143757\n",
      "Loss:  tensor(10928.4619, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[ -9.8552],\n",
      "        [-38.6875]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009416228069143757\n",
      "Loss:  tensor(9888.3965, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[-31.0437],\n",
      "        [-13.7019]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009416228069143757\n",
      "Loss:  tensor(10471.4941, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[-5.8877],\n",
      "        [-6.3755]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009416228069143757\n",
      "Loss:  tensor(10723.0801, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[ -6.8576],\n",
      "        [-36.3733]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009369146928798038\n",
      "Loss:  tensor(9134.6787, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[-4.5867],\n",
      "        [-9.6257]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009369146928798038\n",
      "Loss:  tensor(9604.1094, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[-4.7087],\n",
      "        [-7.7341]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009369146928798038\n",
      "Loss:  tensor(10564.8770, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[-5.4430],\n",
      "        [-4.6438]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009369146928798038\n",
      "Loss:  tensor(10368.5908, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[ -3.1820],\n",
      "        [-28.6029]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009369146928798038\n",
      "Loss:  tensor(10205.3340, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[-10.0714],\n",
      "        [ -2.9911]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009369146928798038\n",
      "Loss:  tensor(10408.6670, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[-3.1014],\n",
      "        [-3.3477]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009369146928798038\n",
      "Loss:  tensor(9162.0371, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[-7.1915],\n",
      "        [-6.1219]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009369146928798038\n",
      "Loss:  tensor(9321.7158, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[-2.1315],\n",
      "        [-4.9839]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009369146928798038\n",
      "Loss:  tensor(9070.5068, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[-5.9383],\n",
      "        [-1.5382]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009369146928798038\n",
      "Loss:  tensor(8297.4346, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[-3.4364],\n",
      "        [-5.6276]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009322301194154048\n",
      "Loss:  tensor(9105.4004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[-1.1182],\n",
      "        [-1.2499]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009322301194154048\n",
      "Loss:  tensor(8728.2002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[-2.2463],\n",
      "        [-2.5343]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009322301194154048\n",
      "Loss:  tensor(8675.8945, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[-43.2123],\n",
      "        [  0.6029]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009322301194154048\n",
      "Loss:  tensor(8220.2939, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[-16.8099],\n",
      "        [  0.2401]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009322301194154048\n",
      "Loss:  tensor(7731.9873, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[ -1.0808],\n",
      "        [-45.3005]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009322301194154048\n",
      "Loss:  tensor(7031.3560, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[0.6346],\n",
      "        [1.6781]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009322301194154048\n",
      "Loss:  tensor(7502.8413, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[0.7208],\n",
      "        [1.1000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009322301194154048\n",
      "Loss:  tensor(7687.6885, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[-10.8563],\n",
      "        [  0.9149]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009322301194154048\n",
      "Loss:  tensor(7013.2710, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[1.6057],\n",
      "        [2.8327]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009322301194154048\n",
      "Loss:  tensor(6135.8154, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[2.1740],\n",
      "        [1.9537]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009275689688183278\n",
      "Loss:  tensor(6747.9688, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[2.8871],\n",
      "        [3.6684]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009275689688183278\n",
      "Loss:  tensor(6961.0703, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[3.2800],\n",
      "        [3.8860]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009275689688183278\n",
      "Loss:  tensor(6835.8311, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[3.9008],\n",
      "        [3.6777]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009275689688183278\n",
      "Loss:  tensor(6593.8594, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[3.4862],\n",
      "        [4.5181]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009275689688183278\n",
      "Loss:  tensor(6905.5166, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[-3.3705],\n",
      "        [ 4.7805]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009275689688183278\n",
      "Loss:  tensor(6790.3999, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[4.3839],\n",
      "        [4.2394]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009275689688183278\n",
      "Loss:  tensor(6070.1191, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[5.1694],\n",
      "        [4.6772]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009275689688183278\n",
      "Loss:  tensor(5818.9023, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[5.0627],\n",
      "        [5.3686]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009275689688183278\n",
      "Loss:  tensor(5867.8999, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[4.7085],\n",
      "        [5.4215]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009275689688183278\n",
      "Loss:  tensor(5470.1357, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[5.1565],\n",
      "        [5.4634]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "1\n",
      "lr:  0.0009229311239742361\n",
      "Loss:  tensor(5919.2285, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "output:  tensor([[5.0531],\n",
      "        [5.4838]], device='cuda:0', grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),])\n",
    "dataset = KwenDataset(path = 'dataset', transform= transform, lstm = True)\n",
    "dataloader =DataLoader(dataset=dataset,batch_size=32,shuffle=True,drop_last=False)\n",
    "def mobilenet(alpha=1, num_classes=1):\n",
    "    return MobileNet(alpha, num_classes)\n",
    "\n",
    "decive = 'cuda'\n",
    "writer = SummaryWriter()\n",
    "losss = {}\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = mobilenet().to(device)\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),])\n",
    "dataset = KwenDataset(path = 'dataset', transform= transform, lstm = True)\n",
    "dataloader =DataLoader(dataset=dataset,batch_size=20,shuffle=True,drop_last=False)\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss().to(device)\n",
    "criterion = nn.MSELoss().to(device)\n",
    "learning_rate = 0.001\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "count_idx = 0\n",
    "\n",
    "for epoch in range(1):\n",
    "    model.train()\n",
    "    print(f\"epoch : {epoch} \")\n",
    "    for batch in dataloader:\n",
    "        img = batch[0]\n",
    "        wqi =batch[1]\n",
    "        label = batch[2]\n",
    "        \n",
    "        label = label.to(torch.float32)\n",
    "        label = label.to(device)\n",
    "        \n",
    "        x_= torch.stack(wqi).to(device)\n",
    "        x_ = torch.transpose(x_,0,1)\n",
    "        x_ = x_.to(torch.float32)\n",
    "\n",
    "        x = img\n",
    "        x = x.to(device)\n",
    "\n",
    "        data = [x, x_]\n",
    "        output = model(data)\n",
    "\n",
    "        loss = criterion(output, label)\n",
    "        \n",
    "        loss = loss.to(torch.float32)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        count_idx += 1\n",
    "        writer.add_scalar('log', loss, count_idx)\n",
    "        losss[count_idx] = loss.item()\n",
    "        print(\"lr: \", optimizer.param_groups[0]['lr'])\n",
    "        print('Loss: ', loss)\n",
    "        print('output: ', output[0:2])\n",
    "        if count_idx%10 == 1 :\n",
    "            optimizer.param_groups[0]['lr'] *= 0.995"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "torch.Size([20, 16])\n",
      "torch.Size([20, 8])\n"
     ]
    }
   ],
   "source": [
    "img = batch[0]\n",
    "wqi =batch[1]\n",
    "\n",
    "x_= torch.stack(wqi).to(device)\n",
    "x_ = torch.transpose(x_,0,1)\n",
    "x_ = x_.to(torch.float32)\n",
    "\n",
    "x = img\n",
    "x = x.to(device)\n",
    "\n",
    "data = [x, x_]\n",
    "result = model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.1963e-05],\n",
       "        [5.1779e-04],\n",
       "        [4.5688e-04],\n",
       "        [4.7213e-04],\n",
       "        [1.3451e-04],\n",
       "        [5.0552e-04],\n",
       "        [3.7219e-04],\n",
       "        [5.8095e-04],\n",
       "        [5.6967e-04],\n",
       "        [4.7185e-04],\n",
       "        [2.5451e-04],\n",
       "        [8.7393e-04],\n",
       "        [6.9446e-04],\n",
       "        [5.5449e-04],\n",
       "        [4.7565e-04],\n",
       "        [3.5057e-04],\n",
       "        [3.1085e-04],\n",
       "        [3.6410e-04],\n",
       "        [5.7352e-04],\n",
       "        [5.9448e-04]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 16])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 8])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 24])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "torch.cat((i, t), dim=1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0177,  0.0094,  0.0121, -0.0026,  0.0048, -0.0031,  0.0027, -0.0009,\n",
       "          0.0031, -0.0010, -0.0042, -0.0099,  0.0093, -0.0033, -0.0023, -0.0021],\n",
       "        [ 0.0170,  0.0107,  0.0082, -0.0009,  0.0144, -0.0100, -0.0051,  0.0061,\n",
       "          0.0035, -0.0075,  0.0014, -0.0095,  0.0001, -0.0052, -0.0042, -0.0060],\n",
       "        [ 0.0176,  0.0072,  0.0102,  0.0055,  0.0057, -0.0077,  0.0006,  0.0052,\n",
       "         -0.0027, -0.0033, -0.0010, -0.0034,  0.0082, -0.0048, -0.0102, -0.0151],\n",
       "        [ 0.0146,  0.0103,  0.0104,  0.0104,  0.0069, -0.0081,  0.0056,  0.0133,\n",
       "         -0.0034, -0.0109, -0.0044, -0.0079,  0.0084, -0.0097, -0.0057, -0.0107],\n",
       "        [ 0.0034,  0.0064,  0.0116,  0.0002,  0.0056, -0.0226,  0.0018,  0.0054,\n",
       "         -0.0006, -0.0088,  0.0039, -0.0047,  0.0014, -0.0018, -0.0045, -0.0003],\n",
       "        [ 0.0107,  0.0081,  0.0074, -0.0023,  0.0078, -0.0123, -0.0035,  0.0013,\n",
       "          0.0027, -0.0036, -0.0042, -0.0061,  0.0088, -0.0057, -0.0018, -0.0064],\n",
       "        [ 0.0142,  0.0087,  0.0137,  0.0002,  0.0102, -0.0126, -0.0013,  0.0029,\n",
       "          0.0028,  0.0034,  0.0021, -0.0136,  0.0036, -0.0096, -0.0040, -0.0069],\n",
       "        [ 0.0134,  0.0054,  0.0057,  0.0033,  0.0035, -0.0108, -0.0028, -0.0008,\n",
       "          0.0022, -0.0003,  0.0013, -0.0132,  0.0135, -0.0165, -0.0114, -0.0073],\n",
       "        [ 0.0075,  0.0163,  0.0180,  0.0012,  0.0191, -0.0290, -0.0197,  0.0189,\n",
       "          0.0187, -0.0066, -0.0112, -0.0317,  0.0131, -0.0203, -0.0052, -0.0263],\n",
       "        [ 0.0129,  0.0095,  0.0048, -0.0035,  0.0087, -0.0102,  0.0021,  0.0111,\n",
       "          0.0030, -0.0004, -0.0010, -0.0065,  0.0051, -0.0093, -0.0045, -0.0062],\n",
       "        [ 0.0157,  0.0093,  0.0105,  0.0028,  0.0065, -0.0051, -0.0012,  0.0086,\n",
       "         -0.0004, -0.0029,  0.0016, -0.0077,  0.0014,  0.0013, -0.0099, -0.0067],\n",
       "        [ 0.0117,  0.0150,  0.0097,  0.0006,  0.0188, -0.0195,  0.0007,  0.0073,\n",
       "          0.0096, -0.0105, -0.0044, -0.0088,  0.0137, -0.0070, -0.0050, -0.0096],\n",
       "        [ 0.0158,  0.0153,  0.0144,  0.0073,  0.0107, -0.0134,  0.0039,  0.0076,\n",
       "         -0.0018, -0.0089,  0.0010, -0.0112,  0.0042, -0.0089, -0.0042, -0.0050],\n",
       "        [ 0.0135,  0.0095,  0.0082,  0.0084,  0.0173, -0.0180,  0.0053,  0.0030,\n",
       "          0.0021, -0.0113, -0.0032, -0.0101,  0.0069, -0.0019, -0.0001, -0.0151],\n",
       "        [ 0.0188,  0.0110,  0.0110, -0.0041,  0.0131, -0.0123,  0.0020,  0.0096,\n",
       "          0.0011, -0.0025,  0.0032, -0.0054,  0.0018, -0.0059, -0.0090, -0.0104],\n",
       "        [-0.0048,  0.0148,  0.0098,  0.0115,  0.0191, -0.0234, -0.0078,  0.0204,\n",
       "         -0.0071, -0.0068, -0.0076, -0.0280,  0.0224, -0.0123,  0.0044, -0.0235],\n",
       "        [ 0.0029,  0.0025,  0.0125,  0.0005,  0.0122, -0.0124,  0.0085,  0.0008,\n",
       "         -0.0038, -0.0058,  0.0009, -0.0026,  0.0077, -0.0036, -0.0006, -0.0180],\n",
       "        [-0.0005,  0.0129,  0.0119, -0.0058,  0.0167, -0.0171,  0.0008,  0.0027,\n",
       "         -0.0026, -0.0057, -0.0016, -0.0205,  0.0068, -0.0099, -0.0055, -0.0146],\n",
       "        [ 0.0127,  0.0111,  0.0139, -0.0007,  0.0072, -0.0127,  0.0061,  0.0019,\n",
       "          0.0017,  0.0010,  0.0042, -0.0096,  0.0088, -0.0098, -0.0059, -0.0039],\n",
       "        [ 0.0157,  0.0131,  0.0105,  0.0021,  0.0156, -0.0108, -0.0016,  0.0049,\n",
       "          0.0121, -0.0029, -0.0007, -0.0174,  0.0047, -0.0032, -0.0126, -0.0098]],\n",
       "       device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0343,  0.0037,  0.0182, -0.0188, -0.0410,  0.0033, -0.0208, -0.0016],\n",
       "        [-0.0354,  0.0016,  0.0183, -0.0185, -0.0417,  0.0038, -0.0211, -0.0024],\n",
       "        [-0.0334,  0.0038,  0.0177, -0.0189, -0.0409,  0.0029, -0.0205, -0.0021],\n",
       "        [-0.0551, -0.0210,  0.0244, -0.0115, -0.0482,  0.0177, -0.0244, -0.0041],\n",
       "        [-0.0520, -0.0155,  0.0354, -0.0155, -0.0565,  0.0070, -0.0301,  0.0089],\n",
       "        [-0.0542,  0.0335,  0.0475, -0.0143, -0.0159,  0.0122, -0.0042,  0.0054],\n",
       "        [-0.0355,  0.0037,  0.0188, -0.0185, -0.0410,  0.0040, -0.0213, -0.0008],\n",
       "        [-0.0343,  0.0038,  0.0182, -0.0187, -0.0409,  0.0034, -0.0208, -0.0015],\n",
       "        [-0.0367,  0.0005,  0.0306, -0.0149, -0.0495,  0.0028, -0.0267,  0.0136],\n",
       "        [-0.0349,  0.0038,  0.0185, -0.0186, -0.0409,  0.0037, -0.0211, -0.0011],\n",
       "        [-0.0358, -0.0003,  0.0181, -0.0188, -0.0423,  0.0038, -0.0207, -0.0040],\n",
       "        [-0.0558, -0.0045,  0.0281, -0.0106, -0.0459,  0.0081, -0.0094, -0.0177],\n",
       "        [-0.0333, -0.0096,  0.0181, -0.0036, -0.0437,  0.0002, -0.0387,  0.0102],\n",
       "        [-0.0235, -0.0039,  0.0139, -0.0056, -0.0413, -0.0045, -0.0352,  0.0074],\n",
       "        [-0.0364, -0.0004,  0.0184, -0.0186, -0.0424,  0.0041, -0.0210, -0.0037],\n",
       "        [-0.0330, -0.0043,  0.0192, -0.0030, -0.0419,  0.0004, -0.0398,  0.0150],\n",
       "        [-0.0359,  0.0110,  0.0241,  0.0032, -0.0382, -0.0027, -0.0249,  0.0058],\n",
       "        [-0.0353, -0.0150,  0.0136, -0.0065, -0.0488,  0.0042, -0.0208,  0.0034],\n",
       "        [-0.0331,  0.0008,  0.0144, -0.0135, -0.0431,  0.0055, -0.0124,  0.0037],\n",
       "        [-0.0285, -0.0003,  0.0140, -0.0107, -0.0352,  0.0052, -0.0123,  0.0033]],\n",
       "       device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
